# -*- coding: utf-8 -*-
"""Sessional-04 Understanding the data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ds6LEV79qJnHsh2GxL0OPsF3O0ZaqP7M

## Part 1: Exploring Brain Size Dataset

### Introduction
Welcome to the fourth lab of the Data Mining course! In this lab, we will work with two datasets to explore various aspects of data manipulation, statistics, and visualization using Python.

### Dataset: Brain Size
The Brain Size dataset contains information about the brain sizes and intelligence scores of 40 individuals. It includes columns such as "Gender," "Age Range," "MRI_Count," and "PIQ" (Performance IQ). We will use this dataset to perform data analysis and visualization.

### 1. Loading Data from CSV File
First, we need to load the data from the CSV file into a Pandas DataFrame.
"""

import pandas as pd

# Load data from CSV file
brain_size_df = pd.read_csv('/content/brain_size.csv')

"""## Summarize the dataset"""

print(brain_size_df.describe())

"""## Print the first some rows of data

"""

print(brain_size_df.head())

"""## Print the Last some rows of data

"""

print(brain_size_df.tail())

"""### 2. Compute Basic Statistics of Given Data
Now, let's compute the basic statistics of the dataset, including its shape, the number of columns, and the mean of the numerical attributes.

"""

# Shape of the DataFrame
shape = brain_size_df.shape
print("Shape of the DataFrame:", shape)

# Number of columns in the DataFrame
num_columns = len(brain_size_df.columns)
print("Number of columns:", num_columns)

# Mean of numerical attributes
mean_values = brain_size_df.mean()
print("Mean values:")
print(mean_values)

"""The basic statistics give us an overview of the dataset, such as its size and the central tendencies of numerical attributes.

### 3. Splitting a DataFrame on Values of Categorical Variables
We can split the DataFrame based on values of categorical variables. For example, we can create separate DataFrames for male and female individuals.

"""

# Split DataFrame based on 'Gender' column
male_df = brain_size_df[brain_size_df['Gender'] == 'Male']
female_df = brain_size_df[brain_size_df['Gender'] == 'Female']


print("\n\n*********************************************************")
print("Number of ele columns:", male_df)


print("\n\n*********************************************************")
print("Number of femele columns:", female_df)

"""Splitting the DataFrame allows us to analyze and compare subsets of data based on certain categories.

### 4. Visualize Data Using Scatter Plot
Let's create a scatter plot to visualize the relationship between brain size (MRI_Count) and performance IQ (PIQ) for all individuals.

"""

import matplotlib.pyplot as plt

# Scatter plot
plt.scatter(brain_size_df['MRI_Count'], brain_size_df['PIQ'])
plt.xlabel('MRI_Count')
plt.ylabel('PIQ')
plt.title('Brain Size vs. Performance IQ')
plt.show()

"""The scatter plot helps us understand whether there is any apparent relationship between brain size and performance IQ in the given dataset.

## Part 2: Exploring Pima Indians Diabetes Dataset

### Dataset: Pima Indians Diabetes
The Pima Indians Diabetes dataset contains information about female patients from the Pima Indian community. It includes columns such as "Pregnancies," "Glucose," "BloodPressure," "SkinThickness," "Insulin," "BMI," "DiabetesPedigreeFunction," and "Age." We will use this dataset to perform data analysis, identify missing data, visualize correlation among attributes, and create a confusion matrix.

### 1. Load Data and Describe Given Data
Let's start by loading the data from the CSV file and describing the dataset, including the basic statistics and identifying missing or outlier data.

"""

# Load data from CSV file
pima_df = pd.read_csv('/content/pima-indians-diabetes.csv')

# Basic statistics of the dataset
description = pima_df.describe()
print(description)

# Identifying missing data
missing_data = pima_df.isnull().sum()
print("Missing Data:")
print(missing_data)

"""Describing the dataset provides us with an understanding of the data distribution and the presence of missing values.

### 2. Find Correlation Among All Attributes
Next, let's find the correlation coefficients among all attributes in the dataset.
"""

# Correlation matrix
correlation_matrix = pima_df.corr()
print("Correlation Matrix:")
print(correlation_matrix)

"""Finding the correlation coefficients helps us understand the relationships between different attributes and their influence on each other.

### 3. Visualize Correlation Matrix
To better understand the correlations among attributes, we can visualize the correlation matrix using a heatmap.

"""

import seaborn as sns

# Visualize correlation matrix using a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix Heatmap')
plt.show()

"""The heatmap provides a visual representation of the correlation coefficients, making it easier to identify strong and weak correlations between attributes.

### 4. Create a Confusion Matrix
A confusion matrix is a useful tool to evaluate the performance of a classification model. Let's create a confusion matrix for the Pima Indians Diabetes dataset.

"""

from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# Split data into features (X) and target (y)
X = pima_df.drop(columns=['Outcome'])
y = pima_df['Outcome']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train a logistic regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Predict using the model
y_pred = model.predict(X_test)

# Create a confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

"""The confusion matrix allows us to analyze the performance of a binary classification model, such as the logistic regression model used in this example.

## Conclusion
Congratulations on completing Lab 4! In this lab, you've learned how to load data from CSV files, compute basic statistics, split data frames based on categorical variables, visualize data using scatter plots and heatmaps, and create a confusion matrix for a classification model.

These skills are essential for data mining, analysis, and visualization tasks. Keep practicing and applying these techniques to real-world datasets. In the next lab, we will cover more advanced data analysis and visualization techniques, including handling missing data, performing data transformations, and building predictive models.

Great job, and keep up the excellent work!
"""